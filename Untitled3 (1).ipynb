{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mQ9E-d-9nf-",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Image importing and initial processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuR1zC0K6u34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d025cb0-569b-4157-b427-f50a0e76412f"
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvLfdd2H631P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70b201ef-70ee-471e-ed23-aab410af22e8"
      },
      "source": [
        "# Importing data from CIFAR-10 dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKAUrN2w7Chp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merging train and test data to make filtering easy\n",
        "\n",
        "import numpy as np\n",
        "images = np.concatenate((train_images, test_images))\n",
        "labels = np.concatenate((train_labels, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_b3ost7KqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cdd9d83-4ac6-40ca-f3dc-7171c95f2b5d"
      },
      "source": [
        "# Verifying shape\n",
        "\n",
        "images.shape, labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 32, 32, 3), (60000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSs92R0W7V_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting labels to 1D vectors\n",
        "\n",
        "labels = labels.reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kskSOYf-7sbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filtering cat images\n",
        "\n",
        "cat_indices = np.where(labels==3)\n",
        "\n",
        "cat_labels = labels[cat_indices[0]]\n",
        "cat_images = images[cat_indices[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9ChEYMH8PgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filtering dog images\n",
        "\n",
        "dog_indices = np.where(labels==5)\n",
        "\n",
        "dog_labels = labels[dog_indices[0]]\n",
        "dog_images = images[dog_indices[0]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjRAvE088kBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating y-values\n",
        "\n",
        "y_1 = [0 for c in cat_labels]\n",
        "y_2 = [1 for d in dog_labels]\n",
        "\n",
        "y = np.concatenate((y_1, y_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Mhs9kQ8_GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merging back our x-values\n",
        "\n",
        "x = np.concatenate((cat_images, dog_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKrgNpWT_WBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing x-values as neural networks work best with numbers between 0 and 1\n",
        "\n",
        "x = x/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twV4aZi89TKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "550a3691-8ca6-40da-8909-0dae7816619e"
      },
      "source": [
        "# Cross checking to see if our slicing and manipulation was successful\n",
        "\n",
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12000, 32, 32, 3), (12000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZUZUybQ9i7Y",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Image augmentation: this step is done to produce more training data as 12,000 images are relatively less**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiat7EJQ9lVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing our image augmentation class\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WSUDLH-mfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmenting our data to produce new images; We will enable vertical-rotation and horizontal-rotation\n",
        "# Splitting data into training set and validation set\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eEPBWgl_Hzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating iterator object that will hold our new images\n",
        "\n",
        "ite = datagen.flow(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uieLatSP_iHC",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Creating our Convolutional Neural Network that will classify the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvy1lZXq_QIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing necessary deep learning modules\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxFLSQMW__yP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "21863b04-0f42-4044-ec22-60aec0e7e879"
      },
      "source": [
        "# Building a deep learning model\n",
        "\n",
        "# There are many hidden layers added to support variability of images\n",
        "\n",
        "#Sequential: the type of model being used\n",
        "#Conv2D: takes in our image and uses a filter to convolve the image and extract features\n",
        "#MaxPooling2D: reduces the spacial size of the tensor that is output by the Conv2D layer to make processing easier\n",
        "#Dropout: ensures that not all of the neurons are activated, preventing overfitting\n",
        "#Flatten: converts tensor to 1D vector so that it can be processed by Dense layer\n",
        "#Dense: outputs the final prediction\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=(32, 32, 3), activation='relu'))\n",
        "model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\", padding=\"same\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pGW3RYcBbqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling our model\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "            optimizer=keras.optimizers.RMSprop(lr=0.0001),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcjGJFMsBnHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "225eab4e-f246-4bdc-edd1-f268543adb67"
      },
      "source": [
        "# Taking a look at how our model looks so far\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,500,705\n",
            "Trainable params: 1,500,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUiFfBpABud-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c56591d-84ce-4bb8-9675-26b5d81ab99d"
      },
      "source": [
        "# Training our model using our augmented data\n",
        "\n",
        "# The number of epochs is the number of times the model goes through the data\n",
        "\n",
        "model.fit(ite, epochs=30)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.3530 - accuracy: 0.8438\n",
            "Epoch 2/30\n",
            "375/375 [==============================] - 120s 320ms/step - loss: 0.3391 - accuracy: 0.8555\n",
            "Epoch 3/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.3382 - accuracy: 0.8523\n",
            "Epoch 4/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.3514 - accuracy: 0.8606\n",
            "Epoch 5/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.3403 - accuracy: 0.8529\n",
            "Epoch 6/30\n",
            "375/375 [==============================] - 122s 325ms/step - loss: 0.3226 - accuracy: 0.8678\n",
            "Epoch 7/30\n",
            "375/375 [==============================] - 121s 323ms/step - loss: 0.3310 - accuracy: 0.8653\n",
            "Epoch 8/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.3162 - accuracy: 0.8729\n",
            "Epoch 9/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.3070 - accuracy: 0.8722\n",
            "Epoch 10/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.3214 - accuracy: 0.8734\n",
            "Epoch 11/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.3168 - accuracy: 0.8707\n",
            "Epoch 12/30\n",
            "375/375 [==============================] - 120s 319ms/step - loss: 0.3025 - accuracy: 0.8826\n",
            "Epoch 13/30\n",
            "375/375 [==============================] - 120s 320ms/step - loss: 0.2901 - accuracy: 0.8836\n",
            "Epoch 14/30\n",
            "375/375 [==============================] - 120s 319ms/step - loss: 0.2916 - accuracy: 0.8819\n",
            "Epoch 15/30\n",
            "375/375 [==============================] - 120s 320ms/step - loss: 0.3027 - accuracy: 0.8844\n",
            "Epoch 16/30\n",
            "375/375 [==============================] - 120s 319ms/step - loss: 0.2754 - accuracy: 0.8895\n",
            "Epoch 17/30\n",
            "375/375 [==============================] - 120s 319ms/step - loss: 0.2707 - accuracy: 0.8923\n",
            "Epoch 18/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.2732 - accuracy: 0.8875\n",
            "Epoch 19/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.2769 - accuracy: 0.8893\n",
            "Epoch 20/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.2731 - accuracy: 0.8907\n",
            "Epoch 21/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.2706 - accuracy: 0.8957\n",
            "Epoch 22/30\n",
            "375/375 [==============================] - 120s 320ms/step - loss: 0.2782 - accuracy: 0.8983\n",
            "Epoch 23/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.2519 - accuracy: 0.9013\n",
            "Epoch 24/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.2406 - accuracy: 0.9057\n",
            "Epoch 25/30\n",
            "375/375 [==============================] - 121s 324ms/step - loss: 0.2789 - accuracy: 0.8990\n",
            "Epoch 26/30\n",
            "375/375 [==============================] - 121s 322ms/step - loss: 0.2704 - accuracy: 0.9035\n",
            "Epoch 27/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.2334 - accuracy: 0.9088\n",
            "Epoch 28/30\n",
            "375/375 [==============================] - 120s 321ms/step - loss: 0.2902 - accuracy: 0.9073\n",
            "Epoch 29/30\n",
            "375/375 [==============================] - 121s 323ms/step - loss: 0.2315 - accuracy: 0.9112\n",
            "Epoch 30/30\n",
            "375/375 [==============================] - 122s 324ms/step - loss: 0.2114 - accuracy: 0.9172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f675a883a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX-NDcaMCLEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quite Impressive! We clock an accuracy of 91% after 30 epochs, which would likely increase given more epochs. \n",
        "\n",
        "#To display results, we will use our helper function"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4iBE-9cWUhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictProbability(new_model, pic):\n",
        "  pic = pic.reshape(1, 32, 32, 3)\n",
        "  num = new_model.predict(pic)[0]\n",
        "  if(num[0]>0.5):\n",
        "    print(\"Dog, {}% sure\".format(num[0]*100))\n",
        "  else:\n",
        "    print(\"Cat, {}% sure\".format(100-num[0]*100))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMTBsIhnWYbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And that's it! Use the function to predict whether an image is a cat or a dog. Feel free to modify the hyperparameters of the network."
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXmf9QqDYhdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6db4fd30-41d4-4d32-ecbe-59c1a11b57fa"
      },
      "source": [
        "# Once you're done and satisied with your model, save it using the following method\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj4cup3SYxf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c1b0ff3f-ccf7-4fcd-c805-5e0e2ff16373"
      },
      "source": [
        "model.save('mymodel.h5')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "  'TensorFlow optimizers do not '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0p3GV3VZE2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni2CrFuVZYw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqAVl_ArZg3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRvOHZhdZqBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}